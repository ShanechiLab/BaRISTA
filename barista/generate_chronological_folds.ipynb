{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d5e7d9f",
   "metadata": {},
   "source": [
    "### Chronological split generation.\n",
    "\n",
    "The following is code used to generate the chronological splits based on the presence of positive and negative samples. This is more of an issue for the speech/sentence tasks, but the same approach is also used for the volume and optical flow tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70411f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6f1fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from barista.data.metadata import Metadata\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b579134b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_metadata(metadata_path):\n",
    "    return Metadata(load_path=metadata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d17fbaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_folds(subject_rows_indices, per_label_subject_rows_indices,\n",
    "                   bucket_size=0.05, step_size=1, base_step_size=1,\n",
    "                   window=4, base_window=1, **folds_kwargss):\n",
    "    assert window % 4 == 0, \"Window should be divisible by 4\"\n",
    "\n",
    "    bucket_len = int(bucket_size * len(subject_rows_indices)) # bucket size in samples\n",
    "    buckets = np.arange(subject_rows_indices[0], subject_rows_indices[-1], bucket_len)\n",
    "    print(f\"Buckets: {buckets}\")\n",
    "\n",
    "    ## Magic number 2 everywhere corresponds to the 0/1 (negative/positive) labels.\n",
    "    ## First, sum the unique label counts per bucket according to the specifications provided.\n",
    "    bucket_counts = [{} for i in range(len(buckets)-1)]\n",
    "    for bucket_ind in range(0, len(bucket_counts), base_step_size):\n",
    "        bucket_start = buckets[bucket_ind]\n",
    "        bucket_end = bucket_start + base_window * bucket_len\n",
    "        for i in range(2):\n",
    "            bucket_counts[bucket_ind][i] = np.sum(np.logical_and(\n",
    "                per_label_subject_rows_indices[i] >= bucket_start,\n",
    "                per_label_subject_rows_indices[i] < bucket_end\n",
    "            ))\n",
    "\n",
    "    ## Count the residual samples in the last bucket.\n",
    "    for i in range(2):\n",
    "        bucket_counts[-1][i] += np.sum(\n",
    "            per_label_subject_rows_indices[i] >= bucket_end\n",
    "        )\n",
    "    print(f\"bucket_counts: {bucket_counts}\")\n",
    "\n",
    "    return _find_folds(bucket_counts, step_size, window, bucket_size, **folds_kwargss)\n",
    "\n",
    "\n",
    "def _find_folds(bucket_counts, step_size, window, bucket_size, num_folds=5):\n",
    "    \"\"\"Logic to find all legitimate folds such that train and test are separated with valid, e.g.,\n",
    "    \n",
    "    [train, valid, test]\n",
    "    [test, valid, train]\n",
    "    [train, valid (0.05), test, valid(0.05), train]\n",
    "    \"\"\"\n",
    "    all_folds, all_folds_splits = [], []\n",
    "    head, tail = 0, len(bucket_counts) - window\n",
    "    use_tail, quad_window = 0, int(window / 4)\n",
    "    while len(all_folds) < num_folds:\n",
    "        curr_ind = tail if use_tail else head\n",
    "        found = False\n",
    "        while not found and curr_ind >= 0 and curr_ind <= len(bucket_counts) - window:\n",
    "            ## Check that any of the validation buckets has both sets of labels.\n",
    "            val_found = False\n",
    "            for check_i in range(quad_window):\n",
    "                val_found |= bucket_counts[curr_ind + check_i][0] > 0 and bucket_counts[curr_ind + check_i][1] > 0\n",
    "            for check_i in range(window - quad_window, window):\n",
    "                val_found |= bucket_counts[curr_ind + check_i][0] > 0 and bucket_counts[curr_ind + check_i][1] > 0\n",
    "\n",
    "            ## Check that any of the test buckets for test data has both labels.\n",
    "            test_found = False\n",
    "            for check_i in range(quad_window, 3*quad_window):\n",
    "                test_found |= bucket_counts[curr_ind + check_i][0] > 0 and bucket_counts[curr_ind + check_i][1] > 0\n",
    "\n",
    "            found = val_found & test_found\n",
    "            if found:\n",
    "                found_ind = curr_ind\n",
    "            curr_ind += -step_size if use_tail else step_size\n",
    "\n",
    "        val_test_interval = np.array([found_ind, found_ind + window]) * bucket_size\n",
    "    \n",
    "        this_fold = [bucket_size, (window-2)*bucket_size, bucket_size]\n",
    "        this_fold_splits = [\"val\", \"test\", \"val\"]\n",
    "        if 1.0 - val_test_interval[-1] > 0:\n",
    "            this_fold.append(1.0 - val_test_interval[-1])\n",
    "            this_fold_splits.append('train')\n",
    "        if val_test_interval[0] > 0:\n",
    "            this_fold = [val_test_interval[0]] + this_fold\n",
    "            this_fold_splits = ['train'] + this_fold_splits\n",
    "\n",
    "        assert np.sum(this_fold) == 1.0\n",
    "        all_folds.append(this_fold)\n",
    "        all_folds_splits.append(this_fold_splits)\n",
    "\n",
    "        if use_tail:\n",
    "            tail = curr_ind - 1 * step_size\n",
    "        else:\n",
    "            head = curr_ind + 1 * step_size\n",
    "        use_tail = 1 - use_tail\n",
    "\n",
    "    return all_folds, all_folds_splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c7aa28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buckets: [   0  154  308  462  616  770  924 1078 1232 1386 1540 1694 1848 2002\n",
      " 2156 2310 2464 2618 2772 2926 3080]\n",
      "bucket_counts: [{0: 68, 1: 86}, {0: 92, 1: 62}, {0: 123, 1: 31}, {0: 42, 1: 112}, {0: 25, 1: 129}, {0: 76, 1: 78}, {0: 65, 1: 89}, {0: 81, 1: 73}, {0: 65, 1: 89}, {0: 33, 1: 121}, {0: 23, 1: 131}, {0: 65, 1: 89}, {0: 75, 1: 79}, {0: 106, 1: 48}, {0: 51, 1: 103}, {0: 103, 1: 51}, {0: 74, 1: 80}, {0: 62, 1: 92}, {0: 154, 1: 0}, {0: 160, 1: 0}]\n",
      "Buckets: [   0  165  330  495  660  825  990 1155 1320 1485 1650 1815 1980 2145\n",
      " 2310 2475 2640 2805 2970 3135]\n",
      "bucket_counts: [{0: 75, 1: 90}, {0: 117, 1: 48}, {0: 116, 1: 49}, {0: 35, 1: 130}, {0: 19, 1: 146}, {0: 40, 1: 125}, {0: 86, 1: 79}, {0: 48, 1: 117}, {0: 115, 1: 50}, {0: 50, 1: 115}, {0: 28, 1: 137}, {0: 26, 1: 139}, {0: 121, 1: 44}, {0: 95, 1: 70}, {0: 73, 1: 92}, {0: 83, 1: 82}, {0: 105, 1: 60}, {0: 88, 1: 77}, {0: 330, 1: 0}]\n",
      "Buckets: [3086 3187 3288 3389 3490 3591 3692 3793 3894 3995 4096 4197 4298 4399\n",
      " 4500 4601 4702 4803 4904 5005 5106]\n",
      "bucket_counts: [{0: 78, 1: 23}, {0: 46, 1: 55}, {0: 68, 1: 33}, {0: 101, 1: 0}, {0: 95, 1: 6}, {0: 30, 1: 71}, {0: 17, 1: 84}, {0: 42, 1: 59}, {0: 25, 1: 76}, {0: 48, 1: 53}, {0: 21, 1: 80}, {0: 31, 1: 70}, {0: 26, 1: 75}, {0: 25, 1: 76}, {0: 74, 1: 27}, {0: 33, 1: 68}, {0: 39, 1: 62}, {0: 59, 1: 42}, {0: 45, 1: 56}, {0: 113, 1: 0}]\n",
      "Buckets: [3300 3588 3876 4164 4452 4740 5028 5316 5604 5892 6180 6468 6756 7044\n",
      " 7332 7620 7908 8196 8484 8772 9060]\n",
      "bucket_counts: [{0: 231, 1: 57}, {0: 124, 1: 164}, {0: 195, 1: 93}, {0: 288, 1: 0}, {0: 246, 1: 42}, {0: 64, 1: 224}, {0: 95, 1: 193}, {0: 85, 1: 203}, {0: 45, 1: 243}, {0: 120, 1: 168}, {0: 42, 1: 246}, {0: 115, 1: 173}, {0: 57, 1: 231}, {0: 71, 1: 217}, {0: 236, 1: 52}, {0: 85, 1: 203}, {0: 109, 1: 179}, {0: 193, 1: 95}, {0: 184, 1: 104}, {0: 302, 1: 0}]\n",
      "Buckets: [5118 5184 5250 5316 5382 5448 5514 5580 5646 5712 5778 5844 5910 5976\n",
      " 6042 6108 6174 6240 6306 6372 6438]\n",
      "bucket_counts: [{0: 66, 1: 0}, {0: 66, 1: 0}, {0: 39, 1: 27}, {0: 46, 1: 20}, {0: 9, 1: 57}, {0: 38, 1: 28}, {0: 13, 1: 53}, {0: 19, 1: 47}, {0: 26, 1: 40}, {0: 20, 1: 46}, {0: 18, 1: 48}, {0: 12, 1: 54}, {0: 28, 1: 38}, {0: 34, 1: 32}, {0: 49, 1: 17}, {0: 28, 1: 38}, {0: 35, 1: 31}, {0: 25, 1: 41}, {0: 19, 1: 47}, {0: 76, 1: 2}]\n",
      "Buckets: [ 9074  9140  9206  9272  9338  9404  9470  9536  9602  9668  9734  9800\n",
      "  9866  9932  9998 10064 10130 10196 10262 10328 10394]\n",
      "bucket_counts: [{0: 66, 1: 0}, {0: 66, 1: 0}, {0: 35, 1: 31}, {0: 58, 1: 8}, {0: 18, 1: 48}, {0: 36, 1: 30}, {0: 9, 1: 57}, {0: 20, 1: 46}, {0: 20, 1: 46}, {0: 22, 1: 44}, {0: 16, 1: 50}, {0: 7, 1: 59}, {0: 18, 1: 48}, {0: 28, 1: 38}, {0: 55, 1: 11}, {0: 39, 1: 27}, {0: 35, 1: 31}, {0: 21, 1: 45}, {0: 19, 1: 47}, {0: 81, 1: 3}]\n",
      "Buckets: [6450 6529 6608 6687 6766 6845 6924 7003 7082 7161 7240 7319 7398 7477\n",
      " 7556 7635 7714 7793 7872 7951 8030]\n",
      "bucket_counts: [{0: 79, 1: 0}, {0: 79, 1: 0}, {0: 64, 1: 15}, {0: 52, 1: 27}, {0: 19, 1: 60}, {0: 51, 1: 28}, {0: 27, 1: 52}, {0: 20, 1: 59}, {0: 9, 1: 70}, {0: 23, 1: 56}, {0: 18, 1: 61}, {0: 56, 1: 23}, {0: 14, 1: 65}, {0: 26, 1: 53}, {0: 6, 1: 73}, {0: 37, 1: 42}, {0: 46, 1: 33}, {0: 25, 1: 54}, {0: 54, 1: 25}, {0: 92, 1: 1}]\n",
      "Buckets: [10412 10509 10606 10703 10800 10897 10994 11091 11188 11285 11382 11479\n",
      " 11576 11673 11770 11867 11964 12061 12158 12255 12352]\n",
      "bucket_counts: [{0: 97, 1: 0}, {0: 86, 1: 11}, {0: 76, 1: 21}, {0: 24, 1: 73}, {0: 53, 1: 44}, {0: 36, 1: 61}, {0: 8, 1: 89}, {0: 17, 1: 80}, {0: 45, 1: 52}, {0: 97, 1: 0}, {0: 69, 1: 28}, {0: 56, 1: 41}, {0: 32, 1: 65}, {0: 21, 1: 76}, {0: 12, 1: 85}, {0: 28, 1: 69}, {0: 39, 1: 58}, {0: 28, 1: 69}, {0: 43, 1: 54}, {0: 110, 1: 1}]\n",
      "Buckets: [8044 8095 8146 8197 8248 8299 8350 8401 8452 8503 8554 8605 8656 8707\n",
      " 8758 8809 8860 8911 8962 9013 9064]\n",
      "bucket_counts: [{0: 51, 1: 0}, {0: 51, 1: 0}, {0: 43, 1: 8}, {0: 4, 1: 47}, {0: 16, 1: 35}, {0: 16, 1: 35}, {0: 18, 1: 33}, {0: 6, 1: 45}, {0: 37, 1: 14}, {0: 42, 1: 9}, {0: 8, 1: 43}, {0: 0, 1: 51}, {0: 24, 1: 27}, {0: 51, 1: 0}, {0: 51, 1: 0}, {0: 28, 1: 23}, {0: 8, 1: 43}, {0: 24, 1: 27}, {0: 12, 1: 39}, {0: 24, 1: 35}]\n",
      "Buckets: [12366 12499 12632 12765 12898 13031 13164 13297 13430 13563 13696 13829\n",
      " 13962 14095 14228 14361 14494 14627 14760 14893 15026]\n",
      "bucket_counts: [{0: 133, 1: 0}, {0: 133, 1: 0}, {0: 74, 1: 59}, {0: 9, 1: 124}, {0: 57, 1: 76}, {0: 22, 1: 111}, {0: 60, 1: 73}, {0: 48, 1: 85}, {0: 71, 1: 62}, {0: 133, 1: 0}, {0: 24, 1: 109}, {0: 15, 1: 118}, {0: 71, 1: 62}, {0: 133, 1: 0}, {0: 133, 1: 0}, {0: 50, 1: 83}, {0: 42, 1: 91}, {0: 30, 1: 103}, {0: 39, 1: 94}, {0: 60, 1: 87}]\n",
      "Buckets: [9072 9112 9152 9192 9232 9272 9312 9352 9392 9432 9472 9512 9552 9592\n",
      " 9632 9672 9712 9752 9792 9832 9872]\n",
      "bucket_counts: [{0: 30, 1: 10}, {0: 29, 1: 11}, {0: 39, 1: 1}, {0: 15, 1: 25}, {0: 12, 1: 28}, {0: 27, 1: 13}, {0: 12, 1: 28}, {0: 16, 1: 24}, {0: 21, 1: 19}, {0: 20, 1: 20}, {0: 17, 1: 23}, {0: 18, 1: 22}, {0: 11, 1: 29}, {0: 15, 1: 25}, {0: 24, 1: 16}, {0: 19, 1: 21}, {0: 17, 1: 23}, {0: 30, 1: 10}, {0: 10, 1: 30}, {0: 24, 1: 28}]\n",
      "Buckets: [15040 15079 15118 15157 15196 15235 15274 15313 15352 15391 15430 15469\n",
      " 15508 15547 15586 15625 15664 15703 15742 15781]\n",
      "bucket_counts: [{0: 35, 1: 4}, {0: 25, 1: 14}, {0: 38, 1: 1}, {0: 17, 1: 22}, {0: 7, 1: 32}, {0: 32, 1: 7}, {0: 12, 1: 27}, {0: 17, 1: 22}, {0: 15, 1: 24}, {0: 14, 1: 25}, {0: 19, 1: 20}, {0: 18, 1: 21}, {0: 7, 1: 32}, {0: 13, 1: 26}, {0: 21, 1: 18}, {0: 17, 1: 22}, {0: 20, 1: 19}, {0: 27, 1: 12}, {0: 36, 1: 42}]\n",
      "Buckets: [ 9884  9942 10000 10058 10116 10174 10232 10290 10348 10406 10464 10522\n",
      " 10580 10638 10696 10754 10812 10870 10928 10986 11044]\n",
      "bucket_counts: [{0: 48, 1: 10}, {0: 39, 1: 19}, {0: 44, 1: 14}, {0: 23, 1: 35}, {0: 27, 1: 31}, {0: 17, 1: 41}, {0: 25, 1: 33}, {0: 9, 1: 49}, {0: 19, 1: 39}, {0: 18, 1: 40}, {0: 58, 1: 0}, {0: 58, 1: 0}, {0: 12, 1: 46}, {0: 13, 1: 45}, {0: 12, 1: 46}, {0: 14, 1: 44}, {0: 25, 1: 33}, {0: 14, 1: 44}, {0: 38, 1: 20}, {0: 76, 1: 0}]\n",
      "Buckets: [15820 15877 15934 15991 16048 16105 16162 16219 16276 16333 16390 16447\n",
      " 16504 16561 16618 16675 16732 16789 16846 16903 16960]\n",
      "bucket_counts: [{0: 48, 1: 9}, {0: 38, 1: 19}, {0: 45, 1: 12}, {0: 19, 1: 38}, {0: 7, 1: 50}, {0: 32, 1: 25}, {0: 22, 1: 35}, {0: 15, 1: 42}, {0: 14, 1: 43}, {0: 16, 1: 41}, {0: 44, 1: 13}, {0: 57, 1: 0}, {0: 21, 1: 36}, {0: 16, 1: 41}, {0: 15, 1: 42}, {0: 13, 1: 44}, {0: 25, 1: 32}, {0: 23, 1: 34}, {0: 41, 1: 16}, {0: 61, 1: 0}]\n"
     ]
    }
   ],
   "source": [
    "## Specify all subjects to compute the chronological folds for.\n",
    "## By default we have the held out sessions (val/test) listed here.\n",
    "ALL_SUBJECTS = [\n",
    "    \"HOLDSUBJ_1_HS1_1\",\n",
    "    \"HOLDSUBJ_2_HS2_6\",\n",
    "    \"HOLDSUBJ_3_HS3_0\",\n",
    "    \"HOLDSUBJ_4_HS4_0\",\n",
    "    \"HOLDSUBJ_6_HS6_4\",\n",
    "    \"HOLDSUBJ_7_HS7_0\",\n",
    "    \"HOLDSUBJ_10_HS10_0\",\n",
    "\n",
    "    # \"SUBJ_2_S2_5\",\n",
    "    # \"SUBJ_4_S4_2\",\n",
    "]\n",
    "\n",
    "## List all the metadata files that correspond to the segments to preprocess. Can optionally use\n",
    "## keyword identifiers for each of the metadata files that need to be processed.\n",
    "_METADATA_FNAMES = {\n",
    "    'default_metadata': 'metadata_ee8e0.csv',\n",
    "}\n",
    "\n",
    "## List all experiments for which the folds should be computed.\n",
    "# _ALL_EXPERIMENTS = [\"sentence_onset_time\", \"speech_vs_nonspeech_time\", \"volume\", \"optical_flow\"]\n",
    "_ALL_EXPERIMENTS = [\"sentence_onset_time\", \"speech_vs_nonspeech_time\"]\n",
    "\n",
    "_SEGMENT_DIR = 'braintreebank_data_segments/{0}'\n",
    "\n",
    "## These are the recommended default settings for computing the folds.\n",
    "bucket_size = 0.05 # Each bucket is 5% duration in samples\n",
    "base_step_size = 1 # We take increments of base_step_size * 5% in samples when constructing buckets.\n",
    "base_window = 1 # Count number of samples per base_window * 5% interval per bucket. Should match base_step_size ideally.\n",
    "step_size = 2 # We take increments of step_size * bucket_size (5%) when looking for buckets.\n",
    "window = 4 # Targeting 20% of data for val and test (i.e., 4 buckets combined for val and test).\n",
    "num_folds = 5 # Number of folds to generate.\n",
    "\n",
    "subject_folds = {}\n",
    "for metadata_setting in _METADATA_FNAMES.keys():\n",
    "    metadata_setting_folds = defaultdict(dict)\n",
    "\n",
    "    for subject_session in ALL_SUBJECTS:\n",
    "        for experiment in _ALL_EXPERIMENTS:\n",
    "\n",
    "            fpath = _SEGMENT_DIR.format(experiment)\n",
    "            metadata_fname = _METADATA_FNAMES[metadata_setting]\n",
    "            metadata = load_metadata(os.path.join(fpath, metadata_fname))\n",
    "\n",
    "            subject_rows_indices = metadata.get_indices_matching_cols_values(\n",
    "                [\"subject_session\", \"experiment\"], [subject_session, experiment]\n",
    "            )\n",
    "\n",
    "            per_label_subject_rows_indices = [0, 0]\n",
    "            for i in range(2): # 2 = negative/positive labels.\n",
    "                per_label_subject_rows_indices[i] = (\n",
    "                    metadata.get_indices_matching_cols_values(\n",
    "                        [\"subject_session\", \"experiment\", \"label\"],\n",
    "                        [subject_session, experiment, i],\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            all_folds, all_folds_splits = generate_folds(\n",
    "                subject_rows_indices,\n",
    "                per_label_subject_rows_indices,\n",
    "                bucket_size,\n",
    "                step_size,\n",
    "                base_step_size,\n",
    "                window,\n",
    "                base_window,\n",
    "                num_folds=num_folds\n",
    "            )\n",
    "\n",
    "            metadata_setting_folds[subject_session][experiment] = (all_folds, all_folds_splits)\n",
    "\n",
    "    subject_folds[metadata_setting] = metadata_setting_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aacfb210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata_setting:default_metadata, subject_session:HOLDSUBJ_1_HS1_1, experiment:sentence_onset_time\n",
      "\n",
      "Run_ratio: [0.05, 0.1, 0.05, 0.8]\n",
      "Split statistics: {'train': Counter({1: 1252, 0: 1218}), 'val': Counter({1: 198, 0: 110}), 'test': Counter({0: 215, 1: 93})}\n",
      "Run_ratio: [0.8, 0.05, 0.1, 0.05]\n",
      "Split statistics: {'train': Counter({1: 1371, 0: 1097}), 'val': Counter({0: 228, 1: 82}), 'test': Counter({0: 218, 1: 90})}\n",
      "Run_ratio: [0.2, 0.05, 0.1, 0.05, 0.6]\n",
      "Split statistics: {'train': Counter({0: 1296, 1: 1174}), 'val': Counter({1: 202, 0: 106}), 'test': Counter({1: 167, 0: 141})}\n",
      "Run_ratio: [0.6000000000000001, 0.05, 0.1, 0.05, 0.19999999999999996]\n",
      "Split statistics: {'train': Counter({1: 1262, 0: 1208}), 'val': Counter({0: 178, 1: 130}), 'test': Counter({0: 157, 1: 151})}\n",
      "Run_ratio: [0.4, 0.05, 0.1, 0.05, 0.3999999999999999]\n",
      "Split statistics: {'train': Counter({0: 1355, 1: 1115}), 'val': Counter({1: 175, 0: 133}), 'test': Counter({1: 253, 0: 55})}\n",
      "\n",
      "\n",
      "metadata_setting:default_metadata, subject_session:HOLDSUBJ_2_HS2_6, experiment:sentence_onset_time\n",
      "\n",
      "Run_ratio: [0.05, 0.1, 0.05, 0.8]\n",
      "Split statistics: {'train': Counter({1: 905, 0: 722}), 'val': Counter({0: 179, 1: 23}), 'test': Counter({0: 115, 1: 88})}\n",
      "Run_ratio: [0.8, 0.05, 0.1, 0.05]\n",
      "Split statistics: {'train': Counter({1: 860, 0: 765}), 'val': Counter({0: 140, 1: 64}), 'test': Counter({0: 111, 1: 92})}\n",
      "Run_ratio: [0.2, 0.05, 0.1, 0.05, 0.6]\n",
      "Split statistics: {'train': Counter({0: 834, 1: 793}), 'val': Counter({0: 133, 1: 69}), 'test': Counter({1: 154, 0: 49})}\n",
      "Run_ratio: [0.6000000000000001, 0.05, 0.1, 0.05, 0.19999999999999996]\n",
      "Split statistics: {'train': Counter({0: 856, 1: 771}), 'val': Counter({1: 146, 0: 56}), 'test': Counter({0: 104, 1: 99})}\n",
      "Run_ratio: [0.4, 0.05, 0.1, 0.05, 0.3999999999999999]\n",
      "Split statistics: {'train': Counter({0: 890, 1: 737}), 'val': Counter({1: 146, 0: 56}), 'test': Counter({1: 133, 0: 70})}\n",
      "\n",
      "\n",
      "metadata_setting:default_metadata, subject_session:HOLDSUBJ_3_HS3_0, experiment:sentence_onset_time\n",
      "\n",
      "Run_ratio: [0.05, 0.1, 0.05, 0.8]\n",
      "Split statistics: {'train': Counter({1: 618, 0: 449}), 'val': Counter({0: 111, 1: 21}), 'test': Counter({0: 106, 1: 27})}\n",
      "Run_ratio: [0.8, 0.05, 0.1, 0.05]\n",
      "Split statistics: {'train': Counter({1: 552, 0: 513}), 'val': Counter({0: 101, 1: 33}), 'test': Counter({1: 81, 0: 52})}\n",
      "Run_ratio: [0.2, 0.05, 0.1, 0.05, 0.6]\n",
      "Split statistics: {'train': Counter({0: 586, 1: 481}), 'val': Counter({1: 104, 0: 28}), 'test': Counter({1: 81, 0: 52})}\n",
      "Run_ratio: [0.6000000000000001, 0.05, 0.1, 0.05, 0.19999999999999996]\n",
      "Split statistics: {'train': Counter({1: 539, 0: 528}), 'val': Counter({1: 76, 0: 56}), 'test': Counter({0: 82, 1: 51})}\n",
      "Run_ratio: [0.4, 0.05, 0.1, 0.05, 0.3999999999999999]\n",
      "Split statistics: {'train': Counter({0: 589, 1: 478}), 'val': Counter({1: 92, 0: 40}), 'test': Counter({1: 96, 0: 37})}\n",
      "\n",
      "\n",
      "metadata_setting:default_metadata, subject_session:HOLDSUBJ_4_HS4_0, experiment:sentence_onset_time\n",
      "\n",
      "Run_ratio: [0.05, 0.1, 0.05, 0.8]\n",
      "Split statistics: {'train': Counter({1: 754, 0: 523}), 'val': Counter({0: 130, 1: 28}), 'test': Counter({0: 144, 1: 15})}\n",
      "Run_ratio: [0.8, 0.05, 0.1, 0.05]\n",
      "Split statistics: {'train': Counter({1: 689, 0: 586}), 'val': Counter({0: 125, 1: 35}), 'test': Counter({0: 86, 1: 73})}\n",
      "Run_ratio: [0.2, 0.05, 0.1, 0.05, 0.6]\n",
      "Split statistics: {'train': Counter({0: 680, 1: 597}), 'val': Counter({1: 119, 0: 39}), 'test': Counter({1: 81, 0: 78})}\n",
      "Run_ratio: [0.6000000000000001, 0.05, 0.1, 0.05, 0.19999999999999996]\n",
      "Split statistics: {'train': Counter({0: 710, 1: 567}), 'val': Counter({1: 102, 0: 56}), 'test': Counter({1: 128, 0: 31})}\n",
      "Run_ratio: [0.4, 0.05, 0.1, 0.05, 0.3999999999999999]\n",
      "Split statistics: {'train': Counter({0: 691, 1: 586}), 'val': Counter({1: 98, 0: 60}), 'test': Counter({1: 113, 0: 46})}\n",
      "\n",
      "\n",
      "metadata_setting:default_metadata, subject_session:HOLDSUBJ_6_HS6_4, experiment:sentence_onset_time\n",
      "\n",
      "Run_ratio: [0.05, 0.1, 0.05, 0.8]\n",
      "Split statistics: {'train': Counter({1: 459, 0: 365}), 'val': Counter({0: 55, 1: 47}), 'test': Counter({0: 94, 1: 8})}\n",
      "Run_ratio: [0.8, 0.05, 0.1, 0.05]\n",
      "Split statistics: {'train': Counter({0: 448, 1: 374}), 'val': Counter({1: 70, 0: 34}), 'test': Counter({1: 70, 0: 32})}\n",
      "Run_ratio: [0.2, 0.05, 0.1, 0.05, 0.6]\n",
      "Split statistics: {'train': Counter({0: 458, 1: 366}), 'val': Counter({1: 79, 0: 23}), 'test': Counter({1: 69, 0: 33})}\n",
      "Run_ratio: [0.5, 0.05, 0.1, 0.05, 0.29999999999999993]\n",
      "Split statistics: {'train': Counter({0: 427, 1: 397}), 'val': Counter({0: 59, 1: 43}), 'test': Counter({1: 74, 0: 28})}\n",
      "Run_ratio: [0.4, 0.05, 0.1, 0.05, 0.3999999999999999]\n",
      "Split statistics: {'train': Counter({0: 427, 1: 397}), 'val': Counter({1: 62, 0: 40}), 'test': Counter({1: 55, 0: 47})}\n",
      "\n",
      "\n",
      "metadata_setting:default_metadata, subject_session:HOLDSUBJ_7_HS7_0, experiment:sentence_onset_time\n",
      "\n",
      "Run_ratio: [0.05, 0.1, 0.05, 0.8]\n",
      "Split statistics: {'train': Counter({1: 358, 0: 293}), 'val': Counter({0: 44, 1: 36}), 'test': Counter({0: 69, 1: 12})}\n",
      "Run_ratio: [0.8, 0.05, 0.1, 0.05]\n",
      "Split statistics: {'train': Counter({0: 330, 1: 319}), 'val': Counter({0: 45, 1: 37}), 'test': Counter({1: 50, 0: 31})}\n",
      "Run_ratio: [0.2, 0.05, 0.1, 0.05, 0.6]\n",
      "Split statistics: {'train': Counter({0: 337, 1: 314}), 'val': Counter({1: 50, 0: 30}), 'test': Counter({1: 42, 0: 39})}\n",
      "Run_ratio: [0.6000000000000001, 0.05, 0.1, 0.05, 0.19999999999999996]\n",
      "Split statistics: {'train': Counter({0: 333, 1: 318}), 'val': Counter({1: 43, 0: 37}), 'test': Counter({1: 45, 0: 36})}\n",
      "Run_ratio: [0.4, 0.05, 0.1, 0.05, 0.3999999999999999]\n",
      "Split statistics: {'train': Counter({0: 331, 1: 320}), 'val': Counter({0: 41, 1: 39}), 'test': Counter({1: 47, 0: 34})}\n",
      "\n",
      "\n",
      "metadata_setting:default_metadata, subject_session:HOLDSUBJ_10_HS10_0, experiment:sentence_onset_time\n",
      "\n",
      "Run_ratio: [0.05, 0.1, 0.05, 0.8]\n",
      "Split statistics: {'train': Counter({1: 510, 0: 435}), 'val': Counter({0: 70, 1: 46}), 'test': Counter({0: 84, 1: 33})}\n",
      "Run_ratio: [0.8, 0.05, 0.1, 0.05]\n",
      "Split statistics: {'train': Counter({1: 495, 0: 447}), 'val': Counter({0: 76, 1: 43}), 'test': Counter({0: 66, 1: 51})}\n",
      "Run_ratio: [0.2, 0.05, 0.1, 0.05, 0.6]\n",
      "Split statistics: {'train': Counter({0: 511, 1: 434}), 'val': Counter({1: 80, 0: 36}), 'test': Counter({1: 75, 0: 42})}\n",
      "Run_ratio: [0.6000000000000001, 0.05, 0.1, 0.05, 0.19999999999999996]\n",
      "Split statistics: {'train': Counter({0: 534, 1: 411}), 'val': Counter({1: 89, 0: 27}), 'test': Counter({1: 89, 0: 28})}\n",
      "Run_ratio: [0.4, 0.05, 0.1, 0.05, 0.3999999999999999]\n",
      "Split statistics: {'train': Counter({1: 509, 0: 436}), 'val': Counter({0: 74, 1: 42}), 'test': Counter({0: 79, 1: 38})}\n",
      "\n",
      "\n",
      "metadata_setting:default_metadata, subject_session:HOLDSUBJ_1_HS1_1, experiment:speech_vs_nonspeech_time\n",
      "\n",
      "Run_ratio: [0.05, 0.1, 0.05, 0.8]\n",
      "Split statistics: {'train': Counter({1: 1333, 0: 1307}), 'val': Counter({1: 220, 0: 110}), 'test': Counter({0: 233, 1: 97})}\n",
      "Run_ratio: [0.75, 0.05, 0.1, 0.05, 0.04999999999999993]\n",
      "Split statistics: {'train': Counter({1: 1431, 0: 1209}), 'val': Counter({0: 248, 1: 82}), 'test': Counter({0: 193, 1: 137})}\n",
      "Run_ratio: [0.2, 0.05, 0.1, 0.05, 0.6]\n",
      "Split statistics: {'train': Counter({0: 1457, 1: 1183}), 'val': Counter({1: 263, 0: 67}), 'test': Counter({1: 204, 0: 126})}\n",
      "Run_ratio: [0.55, 0.05, 0.1, 0.05, 0.25]\n",
      "Split statistics: {'train': Counter({0: 1335, 1: 1305}), 'val': Counter({1: 231, 0: 99}), 'test': Counter({0: 216, 1: 114})}\n",
      "Run_ratio: [0.4, 0.05, 0.1, 0.05, 0.3999999999999999]\n",
      "Split statistics: {'train': Counter({0: 1431, 1: 1209}), 'val': Counter({1: 189, 0: 141}), 'test': Counter({1: 252, 0: 78})}\n",
      "\n",
      "\n",
      "metadata_setting:default_metadata, subject_session:HOLDSUBJ_2_HS2_6, experiment:speech_vs_nonspeech_time\n",
      "\n",
      "Run_ratio: [0.05, 0.1, 0.05, 0.8]\n",
      "Split statistics: {'train': Counter({1: 2573, 0: 2048}), 'val': Counter({0: 519, 1: 57}), 'test': Counter({0: 320, 1: 257})}\n",
      "Run_ratio: [0.8, 0.05, 0.1, 0.05]\n",
      "Split statistics: {'train': Counter({1: 2511, 0: 2108}), 'val': Counter({0: 396, 1: 182}), 'test': Counter({0: 383, 1: 194})}\n",
      "Run_ratio: [0.2, 0.05, 0.1, 0.05, 0.6]\n",
      "Split statistics: {'train': Counter({0: 2399, 1: 2222}), 'val': Counter({0: 329, 1: 247}), 'test': Counter({1: 418, 0: 159})}\n",
      "Run_ratio: [0.6000000000000001, 0.05, 0.1, 0.05, 0.19999999999999996]\n",
      "Split statistics: {'train': Counter({0: 2431, 1: 2190}), 'val': Counter({1: 434, 0: 142}), 'test': Counter({0: 314, 1: 263})}\n",
      "Run_ratio: [0.4, 0.05, 0.1, 0.05, 0.3999999999999999]\n",
      "Split statistics: {'train': Counter({0: 2565, 1: 2056}), 'val': Counter({1: 418, 0: 158}), 'test': Counter({1: 413, 0: 164})}\n",
      "\n",
      "\n",
      "metadata_setting:default_metadata, subject_session:HOLDSUBJ_3_HS3_0, experiment:speech_vs_nonspeech_time\n",
      "\n",
      "Run_ratio: [0.05, 0.1, 0.05, 0.8]\n",
      "Split statistics: {'train': Counter({1: 630, 0: 443}), 'val': Counter({0: 125, 1: 7}), 'test': Counter({0: 101, 1: 32})}\n",
      "Run_ratio: [0.8, 0.05, 0.1, 0.05]\n",
      "Split statistics: {'train': Counter({1: 555, 0: 515}), 'val': Counter({0: 105, 1: 30}), 'test': Counter({1: 84, 0: 49})}\n",
      "Run_ratio: [0.2, 0.05, 0.1, 0.05, 0.6]\n",
      "Split statistics: {'train': Counter({0: 588, 1: 485}), 'val': Counter({1: 95, 0: 37}), 'test': Counter({1: 89, 0: 44})}\n",
      "Run_ratio: [0.6000000000000001, 0.05, 0.1, 0.05, 0.19999999999999996]\n",
      "Split statistics: {'train': Counter({1: 544, 0: 529}), 'val': Counter({1: 85, 0: 47}), 'test': Counter({0: 93, 1: 40})}\n",
      "Run_ratio: [0.4, 0.05, 0.1, 0.05, 0.3999999999999999]\n",
      "Split statistics: {'train': Counter({0: 604, 1: 469}), 'val': Counter({1: 100, 0: 32}), 'test': Counter({1: 100, 0: 33})}\n",
      "\n",
      "\n",
      "metadata_setting:default_metadata, subject_session:HOLDSUBJ_4_HS4_0, experiment:speech_vs_nonspeech_time\n",
      "\n",
      "Run_ratio: [0.05, 0.1, 0.05, 0.8]\n",
      "Split statistics: {'train': Counter({1: 872, 0: 693}), 'val': Counter({0: 122, 1: 72}), 'test': Counter({0: 162, 1: 33})}\n",
      "Run_ratio: [0.8, 0.05, 0.1, 0.05]\n",
      "Split statistics: {'train': Counter({1: 805, 0: 758}), 'val': Counter({0: 146, 1: 50}), 'test': Counter({1: 122, 0: 73})}\n",
      "Run_ratio: [0.2, 0.05, 0.1, 0.05, 0.6]\n",
      "Split statistics: {'train': Counter({0: 863, 1: 702}), 'val': Counter({1: 125, 0: 69}), 'test': Counter({1: 150, 0: 45})}\n",
      "Run_ratio: [0.6000000000000001, 0.05, 0.1, 0.05, 0.19999999999999996]\n",
      "Split statistics: {'train': Counter({0: 883, 1: 682}), 'val': Counter({1: 132, 0: 62}), 'test': Counter({1: 163, 0: 32})}\n",
      "Run_ratio: [0.4, 0.05, 0.1, 0.05, 0.3999999999999999]\n",
      "Split statistics: {'train': Counter({1: 852, 0: 713}), 'val': Counter({0: 102, 1: 92}), 'test': Counter({0: 162, 1: 33})}\n",
      "\n",
      "\n",
      "metadata_setting:default_metadata, subject_session:HOLDSUBJ_6_HS6_4, experiment:speech_vs_nonspeech_time\n",
      "\n",
      "Run_ratio: [0.05, 0.1, 0.05, 0.8]\n",
      "Split statistics: {'train': Counter({1: 1153, 0: 988}), 'val': Counter({0: 142, 1: 124}), 'test': Counter({0: 207, 1: 60})}\n",
      "Run_ratio: [0.8, 0.05, 0.1, 0.05]\n",
      "Split statistics: {'train': Counter({0: 1168, 1: 971}), 'val': Counter({1: 165, 0: 103}), 'test': Counter({1: 201, 0: 66})}\n",
      "Run_ratio: [0.2, 0.05, 0.1, 0.05, 0.6]\n",
      "Split statistics: {'train': Counter({0: 1149, 1: 992}), 'val': Counter({1: 162, 0: 104}), 'test': Counter({1: 183, 0: 84})}\n",
      "Run_ratio: [0.5, 0.05, 0.1, 0.05, 0.29999999999999993]\n",
      "Split statistics: {'train': Counter({0: 1089, 1: 1052}), 'val': Counter({0: 157, 1: 109}), 'test': Counter({1: 176, 0: 91})}\n",
      "Run_ratio: [0.4, 0.05, 0.1, 0.05, 0.3999999999999999]\n",
      "Split statistics: {'train': Counter({0: 1095, 1: 1046}), 'val': Counter({1: 178, 0: 88}), 'test': Counter({0: 154, 1: 113})}\n",
      "\n",
      "\n",
      "metadata_setting:default_metadata, subject_session:HOLDSUBJ_7_HS7_0, experiment:speech_vs_nonspeech_time\n",
      "\n",
      "Run_ratio: [0.05, 0.1, 0.05, 0.8]\n",
      "Split statistics: {'train': Counter({1: 349, 0: 275}), 'val': Counter({0: 52, 1: 26}), 'test': Counter({0: 63, 1: 15})}\n",
      "Run_ratio: [0.75, 0.05, 0.1, 0.05, 0.04999999999999993]\n",
      "Split statistics: {'train': Counter({0: 313, 1: 311}), 'val': Counter({1: 48, 0: 30}), 'test': Counter({0: 47, 1: 31})}\n",
      "Run_ratio: [0.2, 0.05, 0.1, 0.05, 0.6]\n",
      "Split statistics: {'train': Counter({0: 322, 1: 302}), 'val': Counter({1: 54, 0: 24}), 'test': Counter({0: 44, 1: 34})}\n",
      "Run_ratio: [0.55, 0.05, 0.1, 0.05, 0.25]\n",
      "Split statistics: {'train': Counter({0: 331, 1: 293}), 'val': Counter({1: 39, 0: 39}), 'test': Counter({1: 58, 0: 20})}\n",
      "Run_ratio: [0.4, 0.05, 0.1, 0.05, 0.3999999999999999]\n",
      "Split statistics: {'train': Counter({0: 324, 1: 300}), 'val': Counter({1: 45, 0: 33}), 'test': Counter({1: 45, 0: 33})}\n",
      "\n",
      "\n",
      "metadata_setting:default_metadata, subject_session:HOLDSUBJ_10_HS10_0, experiment:speech_vs_nonspeech_time\n",
      "\n",
      "Run_ratio: [0.05, 0.1, 0.05, 0.8]\n",
      "Split statistics: {'train': Counter({1: 494, 0: 422}), 'val': Counter({0: 67, 1: 47}), 'test': Counter({0: 83, 1: 31})}\n",
      "Run_ratio: [0.8, 0.05, 0.1, 0.05]\n",
      "Split statistics: {'train': Counter({1: 493, 0: 422}), 'val': Counter({0: 83, 1: 32}), 'test': Counter({0: 67, 1: 47})}\n",
      "Run_ratio: [0.2, 0.05, 0.1, 0.05, 0.6]\n",
      "Split statistics: {'train': Counter({0: 496, 1: 420}), 'val': Counter({1: 92, 0: 22}), 'test': Counter({1: 60, 0: 54})}\n",
      "Run_ratio: [0.6000000000000001, 0.05, 0.1, 0.05, 0.19999999999999996]\n",
      "Split statistics: {'train': Counter({0: 509, 1: 407}), 'val': Counter({1: 82, 0: 32}), 'test': Counter({1: 83, 0: 31})}\n",
      "Run_ratio: [0.4, 0.05, 0.1, 0.05, 0.3999999999999999]\n",
      "Split statistics: {'train': Counter({1: 476, 0: 440}), 'val': Counter({0: 71, 1: 43}), 'test': Counter({0: 61, 1: 53})}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Following code will compute the statistics associated with each fold.\n",
    "all_output_dicts = {}\n",
    "for metadata_setting in _METADATA_FNAMES.keys():\n",
    "    output_dict = {} # {experiment_name: {subject_session: [(ratio1, split1), (ratio2, split2), ...]}}\n",
    "    for experiment in _ALL_EXPERIMENTS:\n",
    "        output_dict[experiment] = {}\n",
    "\n",
    "        fpath = _SEGMENT_DIR.format(experiment)\n",
    "        metadata_fname = _METADATA_FNAMES[metadata_setting]\n",
    "        metadata = load_metadata(os.path.join(fpath, metadata_fname))\n",
    "\n",
    "        for subject_session in ALL_SUBJECTS:\n",
    "            print(\n",
    "                f'metadata_setting:{metadata_setting}, '\n",
    "                f'subject_session:{subject_session}, '\n",
    "                f'experiment:{experiment}\\n'\n",
    "            )\n",
    "\n",
    "            subject_rows_indices = metadata.get_indices_matching_cols_values(\n",
    "                [\"subject_session\", \"experiment\"], [subject_session, experiment]\n",
    "            )\n",
    "            n_segments = len(subject_rows_indices)\n",
    "\n",
    "            folds, splits = subject_folds[metadata_setting][subject_session][experiment]\n",
    "            out_tuples = []\n",
    "            for run_ratio, run_splits in zip(folds, splits):\n",
    "                counts = (np.array(run_ratio) * n_segments).astype(int)\n",
    "                counts[-1] = n_segments - sum(counts[:-1])\n",
    "\n",
    "                print(f\"Run_ratio: {run_ratio}\")\n",
    "\n",
    "                agg_split_counts = {'train': Counter(), 'val': Counter(), 'test': Counter()}\n",
    "                sum_now = 0\n",
    "                for c, split in zip(counts, run_splits):\n",
    "                    label_split_indices = subject_rows_indices[sum_now : sum_now + c]\n",
    "                    sum_now += c\n",
    "                    agg_split_counts[split].update(\n",
    "                        metadata._df.iloc[label_split_indices].label.to_numpy()\n",
    "                    )\n",
    "\n",
    "                print(f'Split statistics: {agg_split_counts}')\n",
    "                out_tuples.append((run_ratio, run_splits))\n",
    "            print('\\n')\n",
    "\n",
    "            output_dict[experiment][subject_session] = out_tuples\n",
    "\n",
    "    all_output_dicts[metadata_setting] = output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22372166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/seyedesa/njepa/public_release_test/data_nov30_15_00/sentence_onset_time\n",
      "/data/seyedesa/njepa/public_release_test/data_nov30_15_00/speech_vs_nonspeech_time\n"
     ]
    }
   ],
   "source": [
    "## Save out the data in the format expected in braintreebank_dataset.py.\n",
    "import pickle\n",
    "\n",
    "for fb_setting, fb_setting_output in all_output_dicts.items():\n",
    "    out_fname = f\"{Path(_METADATA_FNAMES[fb_setting]).stem}_folds.pkl\"\n",
    "\n",
    "    for experiment, experiment_output in fb_setting_output.items():\n",
    "        out_path = _SEGMENT_DIR.format(experiment)\n",
    "        print(out_path)\n",
    "        with open(os.path.join(out_path, out_fname), 'wb') as file:\n",
    "            pickle.dump(experiment_output, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e6e1189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence_onset_time\n",
      "{'HOLDSUBJ_1_HS1_1': [([0.05, 0.1, 0.05, 0.8], ['val', 'test', 'val', 'train']), ([0.8, 0.05, 0.1, 0.05], ['train', 'val', 'test', 'val']), ([0.2, 0.05, 0.1, 0.05, 0.6], ['train', 'val', 'test', 'val', 'train']), ([0.6000000000000001, 0.05, 0.1, 0.05, 0.19999999999999996], ['train', 'val', 'test', 'val', 'train']), ([0.4, 0.05, 0.1, 0.05, 0.3999999999999999], ['train', 'val', 'test', 'val', 'train'])], 'HOLDSUBJ_2_HS2_6': [([0.05, 0.1, 0.05, 0.8], ['val', 'test', 'val', 'train']), ([0.8, 0.05, 0.1, 0.05], ['train', 'val', 'test', 'val']), ([0.2, 0.05, 0.1, 0.05, 0.6], ['train', 'val', 'test', 'val', 'train']), ([0.6000000000000001, 0.05, 0.1, 0.05, 0.19999999999999996], ['train', 'val', 'test', 'val', 'train']), ([0.4, 0.05, 0.1, 0.05, 0.3999999999999999], ['train', 'val', 'test', 'val', 'train'])], 'HOLDSUBJ_3_HS3_0': [([0.05, 0.1, 0.05, 0.8], ['val', 'test', 'val', 'train']), ([0.8, 0.05, 0.1, 0.05], ['train', 'val', 'test', 'val']), ([0.2, 0.05, 0.1, 0.05, 0.6], ['train', 'val', 'test', 'val', 'train']), ([0.6000000000000001, 0.05, 0.1, 0.05, 0.19999999999999996], ['train', 'val', 'test', 'val', 'train']), ([0.4, 0.05, 0.1, 0.05, 0.3999999999999999], ['train', 'val', 'test', 'val', 'train'])], 'HOLDSUBJ_4_HS4_0': [([0.05, 0.1, 0.05, 0.8], ['val', 'test', 'val', 'train']), ([0.8, 0.05, 0.1, 0.05], ['train', 'val', 'test', 'val']), ([0.2, 0.05, 0.1, 0.05, 0.6], ['train', 'val', 'test', 'val', 'train']), ([0.6000000000000001, 0.05, 0.1, 0.05, 0.19999999999999996], ['train', 'val', 'test', 'val', 'train']), ([0.4, 0.05, 0.1, 0.05, 0.3999999999999999], ['train', 'val', 'test', 'val', 'train'])], 'HOLDSUBJ_6_HS6_4': [([0.05, 0.1, 0.05, 0.8], ['val', 'test', 'val', 'train']), ([0.8, 0.05, 0.1, 0.05], ['train', 'val', 'test', 'val']), ([0.2, 0.05, 0.1, 0.05, 0.6], ['train', 'val', 'test', 'val', 'train']), ([0.5, 0.05, 0.1, 0.05, 0.29999999999999993], ['train', 'val', 'test', 'val', 'train']), ([0.4, 0.05, 0.1, 0.05, 0.3999999999999999], ['train', 'val', 'test', 'val', 'train'])], 'HOLDSUBJ_7_HS7_0': [([0.05, 0.1, 0.05, 0.8], ['val', 'test', 'val', 'train']), ([0.8, 0.05, 0.1, 0.05], ['train', 'val', 'test', 'val']), ([0.2, 0.05, 0.1, 0.05, 0.6], ['train', 'val', 'test', 'val', 'train']), ([0.6000000000000001, 0.05, 0.1, 0.05, 0.19999999999999996], ['train', 'val', 'test', 'val', 'train']), ([0.4, 0.05, 0.1, 0.05, 0.3999999999999999], ['train', 'val', 'test', 'val', 'train'])], 'HOLDSUBJ_10_HS10_0': [([0.05, 0.1, 0.05, 0.8], ['val', 'test', 'val', 'train']), ([0.8, 0.05, 0.1, 0.05], ['train', 'val', 'test', 'val']), ([0.2, 0.05, 0.1, 0.05, 0.6], ['train', 'val', 'test', 'val', 'train']), ([0.6000000000000001, 0.05, 0.1, 0.05, 0.19999999999999996], ['train', 'val', 'test', 'val', 'train']), ([0.4, 0.05, 0.1, 0.05, 0.3999999999999999], ['train', 'val', 'test', 'val', 'train'])]}\n",
      "\n",
      "\n",
      "speech_vs_nonspeech_time\n",
      "{'HOLDSUBJ_1_HS1_1': [([0.05, 0.1, 0.05, 0.8], ['val', 'test', 'val', 'train']), ([0.75, 0.05, 0.1, 0.05, 0.04999999999999993], ['train', 'val', 'test', 'val', 'train']), ([0.2, 0.05, 0.1, 0.05, 0.6], ['train', 'val', 'test', 'val', 'train']), ([0.55, 0.05, 0.1, 0.05, 0.25], ['train', 'val', 'test', 'val', 'train']), ([0.4, 0.05, 0.1, 0.05, 0.3999999999999999], ['train', 'val', 'test', 'val', 'train'])], 'HOLDSUBJ_2_HS2_6': [([0.05, 0.1, 0.05, 0.8], ['val', 'test', 'val', 'train']), ([0.8, 0.05, 0.1, 0.05], ['train', 'val', 'test', 'val']), ([0.2, 0.05, 0.1, 0.05, 0.6], ['train', 'val', 'test', 'val', 'train']), ([0.6000000000000001, 0.05, 0.1, 0.05, 0.19999999999999996], ['train', 'val', 'test', 'val', 'train']), ([0.4, 0.05, 0.1, 0.05, 0.3999999999999999], ['train', 'val', 'test', 'val', 'train'])], 'HOLDSUBJ_3_HS3_0': [([0.05, 0.1, 0.05, 0.8], ['val', 'test', 'val', 'train']), ([0.8, 0.05, 0.1, 0.05], ['train', 'val', 'test', 'val']), ([0.2, 0.05, 0.1, 0.05, 0.6], ['train', 'val', 'test', 'val', 'train']), ([0.6000000000000001, 0.05, 0.1, 0.05, 0.19999999999999996], ['train', 'val', 'test', 'val', 'train']), ([0.4, 0.05, 0.1, 0.05, 0.3999999999999999], ['train', 'val', 'test', 'val', 'train'])], 'HOLDSUBJ_4_HS4_0': [([0.05, 0.1, 0.05, 0.8], ['val', 'test', 'val', 'train']), ([0.8, 0.05, 0.1, 0.05], ['train', 'val', 'test', 'val']), ([0.2, 0.05, 0.1, 0.05, 0.6], ['train', 'val', 'test', 'val', 'train']), ([0.6000000000000001, 0.05, 0.1, 0.05, 0.19999999999999996], ['train', 'val', 'test', 'val', 'train']), ([0.4, 0.05, 0.1, 0.05, 0.3999999999999999], ['train', 'val', 'test', 'val', 'train'])], 'HOLDSUBJ_6_HS6_4': [([0.05, 0.1, 0.05, 0.8], ['val', 'test', 'val', 'train']), ([0.8, 0.05, 0.1, 0.05], ['train', 'val', 'test', 'val']), ([0.2, 0.05, 0.1, 0.05, 0.6], ['train', 'val', 'test', 'val', 'train']), ([0.5, 0.05, 0.1, 0.05, 0.29999999999999993], ['train', 'val', 'test', 'val', 'train']), ([0.4, 0.05, 0.1, 0.05, 0.3999999999999999], ['train', 'val', 'test', 'val', 'train'])], 'HOLDSUBJ_7_HS7_0': [([0.05, 0.1, 0.05, 0.8], ['val', 'test', 'val', 'train']), ([0.75, 0.05, 0.1, 0.05, 0.04999999999999993], ['train', 'val', 'test', 'val', 'train']), ([0.2, 0.05, 0.1, 0.05, 0.6], ['train', 'val', 'test', 'val', 'train']), ([0.55, 0.05, 0.1, 0.05, 0.25], ['train', 'val', 'test', 'val', 'train']), ([0.4, 0.05, 0.1, 0.05, 0.3999999999999999], ['train', 'val', 'test', 'val', 'train'])], 'HOLDSUBJ_10_HS10_0': [([0.05, 0.1, 0.05, 0.8], ['val', 'test', 'val', 'train']), ([0.8, 0.05, 0.1, 0.05], ['train', 'val', 'test', 'val']), ([0.2, 0.05, 0.1, 0.05, 0.6], ['train', 'val', 'test', 'val', 'train']), ([0.6000000000000001, 0.05, 0.1, 0.05, 0.19999999999999996], ['train', 'val', 'test', 'val', 'train']), ([0.4, 0.05, 0.1, 0.05, 0.3999999999999999], ['train', 'val', 'test', 'val', 'train'])]}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Checking output was correct.\n",
    "for fb_setting, fb_setting_output in all_output_dicts.items():\n",
    "    out_fname = f\"{Path(_METADATA_FNAMES[fb_setting]).stem}_folds.pkl\"\n",
    "\n",
    "    for experiment, experiment_output in fb_setting_output.items():\n",
    "        out_path = _SEGMENT_DIR.format(experiment)\n",
    "        with open(os.path.join(out_path, out_fname), 'rb') as file:\n",
    "            datatmp = pickle.load(file)\n",
    "        print(experiment)\n",
    "        print(datatmp)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77052232",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
